{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33e55be-ed84-41d7-bdba-16e3310caacf",
   "metadata": {},
   "source": [
    "## 1. Load User Data from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4767633-edbd-40e1-b129-629f2e28d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "# Read u.user from HDFS\n",
    "user_rdd = sc.textFile(\"hdfs:///user/maria_dev/movielens/u.user\")\n",
    "\n",
    "# Parse into structured data\n",
    "from pyspark.sql import Row\n",
    "\n",
    "user_df = user_rdd.map(lambda line: line.split(\"|\")) \\\n",
    "    .map(lambda parts: Row(\n",
    "        userid=int(parts[0]),\n",
    "        age=int(parts[1]),\n",
    "        gender=parts[2],\n",
    "        occupation=parts[3],\n",
    "        zipcode=parts[4])\n",
    "    ).toDF()\n",
    "\n",
    "# Display the first few records\n",
    "user_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d46d57-3bae-44d4-8cbe-a6e8bb10ef7c",
   "metadata": {},
   "source": [
    "## 2. Rename Columns and Write to Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c131ef-3ab7-4da5-8d87-dedcfbfa3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "# Change the column names from userid → user_id, zipcode → zip\n",
    "renamed_df = user_df \\\n",
    "    .withColumnRenamed(\"userid\", \"user_id\") \\\n",
    "    .withColumnRenamed(\"zipcode\", \"zip\")\n",
    "\n",
    "# Writing to Cassandra\n",
    "renamed_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"keyspace\", \"movielens\") \\\n",
    "    .option(\"table\", \"users\") \\\n",
    "    .option(\"spark.cassandra.connection.host\", \"127.0.0.1\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45420b5e-cc41-4439-9719-f1cc5dc57fc2",
   "metadata": {},
   "source": [
    "## 3. Load User Data from Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799cb2db-c7d9-454b-a47d-8fb4adac968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "df_from_cassandra = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .option(\"keyspace\", \"movielens\") \\\n",
    "    .option(\"table\", \"users\") \\\n",
    "    .option(\"spark.cassandra.connection.host\", \"127.0.0.1\") \\\n",
    "    .load()\n",
    "\n",
    "df_from_cassandra.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef9ceae-e180-4ecc-acfa-727fe8429373",
   "metadata": {},
   "source": [
    "## 4. Load and Parse Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bade1-d426-4521-901c-9b5eeac0b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "\n",
    "# 1. Read the rating data u.data from HDFS\n",
    "rating_rdd = sc.textFile(\"hdfs:///user/maria_dev/movielens/u.data\")\n",
    "\n",
    "# 2. Convert to structured Row\n",
    "from pyspark.sql import Row\n",
    "\n",
    "rating_df = rating_rdd.map(lambda line: line.split(\"\\t\")) \\\n",
    "    .map(lambda parts: Row(\n",
    "        user_id=int(parts[0]),\n",
    "        item_id=int(parts[1]),\n",
    "        rating=int(parts[2]))\n",
    "    ).toDF()\n",
    "\n",
    "# 3. Display the first few rating data\n",
    "rating_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb8aa81-20e8-49dd-8b83-1460f21c1e40",
   "metadata": {},
   "source": [
    "## 5. Average Rating per Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a8c1a-1329-4245-92eb-bea711b19914",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Group by item_id and calculate the average rating\n",
    "avg_ratings_df = rating_df.groupBy(\"item_id\").agg(avg(\"rating\").alias(\"avg_rating\"))\n",
    "\n",
    "# Display the first 10 results\n",
    "avg_ratings_df.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784f5de-736f-42ea-826d-dc26575c9f97",
   "metadata": {},
   "source": [
    "## 6. Load Movie Titles from u.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2be54c-ae92-43ce-9137-787eeff14b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "# Read u.item file\n",
    "item_rdd = sc.textFile(\"hdfs:///user/maria_dev/movielens/u.item\")\n",
    "\n",
    "# Take the first two fields: movie_id and title\n",
    "from pyspark.sql import Row\n",
    "\n",
    "item_df = item_rdd.map(lambda line: line.split(\"|\")) \\\n",
    "    .map(lambda parts: Row(\n",
    "        item_id=int(parts[0]),\n",
    "        title=parts[1])\n",
    "    ).toDF()\n",
    "\n",
    "item_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd76529-e429-45fd-b4ea-e85e302528c6",
   "metadata": {},
   "source": [
    "## 7. Join Movie Titles with Average Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430312e-1c5f-4477-8b64-af2cc571a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "# Join the average movie rating with the movie name\n",
    "joined_df = avg_ratings_df.join(item_df, on=\"item_id\")\n",
    "\n",
    "# Display the first 10 results\n",
    "joined_df.select(\"title\", \"avg_rating\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328265b-8caf-42bd-8d2e-27ad903dae83",
   "metadata": {},
   "source": [
    "## 8. Top 10 Highest Rated Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0adcb3c-f71b-4e0a-96df-a9f9e47cddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "# Top 10 highest rated movies\n",
    "top10_movies = joined_df.select(\"title\", \"avg_rating\") \\\n",
    "    .orderBy(\"avg_rating\", ascending=False)\n",
    "\n",
    "top10_movies.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b9ce7c-1f04-407d-a58c-51dc2e8c6711",
   "metadata": {},
   "source": [
    "## 9. Movies with ≥ 50 Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a4f7d4-cccf-41f8-b669-ee932d023795",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "# Find the average rating and number of ratings for each movie\n",
    "movie_stats_df = rating_df.groupBy(\"item_id\") \\\n",
    "    .agg(\n",
    "        avg(\"rating\").alias(\"avg_rating\"),\n",
    "        count(\"rating\").alias(\"num_ratings\")\n",
    "    )\n",
    "\n",
    "# Add movie name\n",
    "movie_stats_with_title = movie_stats_df.join(item_df, on=\"item_id\")\n",
    "\n",
    "# Display the top 10 movies with the highest ratings and times >= 50\n",
    "movie_stats_with_title.filter(\"num_ratings >= 50\") \\\n",
    "    .orderBy(\"avg_rating\", ascending=False) \\\n",
    "    .select(\"title\", \"avg_rating\", \"num_ratings\") \\\n",
    "    .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70602a-3565-4720-ad36-e6e83d3ef08c",
   "metadata": {},
   "source": [
    "## 10. Active Users with ≥ 50 Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e5217-6f23-4696-b84e-eb5000e26544",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Number of movies rated by each user\n",
    "user_rating_count = rating_df.groupBy(\"user_id\") \\\n",
    "    .agg(count(\"item_id\").alias(\"num_rated\"))\n",
    "\n",
    "# Only keep users with a rating ≥ 50\n",
    "active_users = user_rating_count.filter(\"num_rated >= 50\")\n",
    "\n",
    "active_users.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199cb12-d07e-4b33-bf1f-418bdf945c42",
   "metadata": {},
   "source": [
    "## 11. Extract Movie Genres and Expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c1860-1573-422c-96c5-2fb969e06e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "# Names of all movie genres (MovieLens 19 genres)s）\n",
    "genre_list = [\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\",\n",
    "    \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\",\n",
    "    \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "# Read u.item, extract item_id and type flag\n",
    "item_rdd = sc.textFile(\"hdfs:///user/maria_dev/movielens/u.item\")\n",
    "\n",
    "# Split one-hot types into multiple lines: (item_id, genre) format\n",
    "genre_expanded_rdd = item_rdd.map(lambda line: line.split(\"|\")) \\\n",
    "    .flatMap(lambda parts: [\n",
    "        (int(parts[0]), genre_list[i]) \n",
    "        for i in range(19) if parts[5+i] == \"1\"\n",
    "    ])\n",
    "\n",
    "# Convert to DataFrame: column names are item_id, genre\n",
    "genre_df = genre_expanded_rdd.toDF([\"item_id\", \"genre\"])\n",
    "\n",
    "genre_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da411434-e807-43ce-afa3-cbfae7570d96",
   "metadata": {},
   "source": [
    "## 12. Most Preferred Genre per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa038fb-718d-41d7-a0ac-c9dc161d87f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "from pyspark.sql.functions import count, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Step 5: Join the rating data with the movie genre\n",
    "user_genre_df = rating_df.join(genre_df, on=\"item_id\")\n",
    "\n",
    "# Step 6: Only keep users with a rating ≥ 50\n",
    "filtered_user_genre = user_genre_df.join(active_users, on=\"user_id\")\n",
    "\n",
    "# Count the number of times each user rates each type\n",
    "user_genre_count = filtered_user_genre.groupBy(\"user_id\", \"genre\") \\\n",
    "    .agg(count(\"*\").alias(\"genre_count\"))\n",
    "\n",
    "# Use window functions to find the most rated types for each user\n",
    "window_spec = Window.partitionBy(\"user_id\").orderBy(user_genre_count[\"genre_count\"].desc())\n",
    "\n",
    "top_genre_per_user = user_genre_count \\\n",
    "    .withColumn(\"rank\", row_number().over(window_spec)) \\\n",
    "    .filter(\"rank = 1\") \\\n",
    "    .select(\"user_id\", \"genre\", \"genre_count\")\n",
    "\n",
    "top_genre_per_user.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e58a9-c395-46fb-bca6-9a0a6e56daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. Users Younger than 20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
